{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Wealth of Cities\n",
    "## Predicting the Wealth of a City from Satellite Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Accurate measurements of the economic characteristics of cities critically influence research and government policy (Jean, Luo). Such measurements can shape decisions by governments on how to allocate resources and provide infrastructure to improve human livelihoods in a wide-range of situations. Although economic data is readily available for most developed and some developing nations, many regions of the modern world remain unexposed to the benefits of economic analysis because of a lack key measures of economic development and efficiency. Regions such as parts of Africa do not have systems in place to conduct economic surveys or other means of collecting data on their financial situations. In our project we attempt to address this problem by using publicly available satellite images to predict the wealth of a city (or, more generally, a geographic region) based on fundamental features identified in these images and running them through a support vector machine(SVM). Not only would this method be applicable to regions that lack economic data, but could also be applied to cities with a wealth of economic information on a macro level but a dearth on a micro level. For example, cities in America, despite having lots of economic data on state and county levels, could benefit from understanding more granular information in order to improve policy decisions for infrastructure and public support. \n",
    "\n",
    "\n",
    "## Related Work\n",
    "\n",
    "Night-Time Light Data: A Good Proxy Measure for Economic Activity?\n",
    "Charlotta Mellander, International Business School, Jönköping University, Sweden\n",
    "José Lobo, School of Human Evolution and Social Change, Arizona State University, USA\n",
    "Kevin Stolarick, Inclusive Design Research Centre, OCAD University, Canada\n",
    "Zara Matheson, Former Martin Prosperity Institute, Rotman School of Management, University of Toronto, Canada\n",
    "http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0139779\n",
    "\n",
    "Authors of this paper investigated how economic metrics like density, urbanisation, economic growth are related to Night Time Lighting obtained from Satellite Images. They used a \"fine grained geo-coded residential and industrial full sample micro-data set for Sweden\" and then used correlation analysis and geographically weighted regressions to match it with radiance and saturated light emissions. Interestingly they found that \"correlation between NTL and economic activity is strong enough to make it a relatively good proxy for population and establishment density, but the correlation is weaker in relation to wages.\" Further, they said that they find a \"stronger relation between light and density values, than with light and total values. We also find a closer connection between radiance light and economic activity, than with saturated light.\" \n",
    "\n",
    "\n",
    "Finding Poverty in Satellite Images \n",
    "Neal Jean, Stanford University, California, USA\n",
    "Rachel Luo, Stanford University, California, USA\n",
    "http://cs229.stanford.edu/proj2015/162_report.pdf\n",
    "\n",
    "This paper uses only day time satellite images because the authors discovered that NTL is almost completely absent in very poor and rural areas, which makes it impossible to gauge economic activity of these regions with night time images. In this study, the authors took the output of a convolutional neural network (CNN), a 4,096-element feature vector, and use these image features along with known survey data from certain parts of Uganda and Tanzania to perform linear regression on continuous wealth measures. Next, they use this model to predict both consumption-based and asset-based wealth measures, and they find that their predictions do in fact \"approach survey accuracy.\"\n",
    "\n",
    "\n",
    "We take inspiration from both these works and try to extract features and use machine learning techniques that are most feasible for the nature and scale for our project. \n",
    "\n",
    "\n",
    "## Features\n",
    "\n",
    "In order for this approach to work, we need to be able to extract relevant features from the images in order to train our machine learning model. Our model will not be able to predict the wealth of individual houses (i.e., families), but will work on clusters of houses (i.e., neighborhoods and cities) because of the complexity of wealth measurements and tendency for neighborhood to be at a nearly homogeneous economic level. As a result, we will need to extract \"cluster\" features to process with our SVM.\n",
    "\n",
    "Features of satellite images that we extract to elucidate the wealth of a region are:\n",
    "1. Night Time Lighting\n",
    "2. Percentage of Special Area types\n",
    "3. Number of Cars\n",
    "\n",
    "### Night Time Lighting \n",
    "\n",
    "This feature has been widely researched and turns out to be a relatively good indicator of economic activity of a region. Many studies have been done to assets to what extent does Night Time Lighting, and its sub-features like radiance and saturation, relate to economic activity and population density. Mellander et al. in their paper \"Night-Time Light Data: A Good Proxy Measure for Economic Activity?\" say that \"We find that the correlation between NTL and economic activity is strong enough to make it a relatively good proxy for population and establishment density, but the correlation is weaker in relation to wages.\" In this project we wish to use NTL in tandem with our other features to see whether we can predict average wages of a area more accurately. \n",
    "\n",
    "We use high resolution Night Images taken by Earth Observatory NASA in 2012. The collection, called Earth at Night 2012, can be found here: http://earthobservatory.nasa.gov/Features/NightLights/page3.php . These are a collection of 9 images: one map-like image of the whole earth of resolution 54000x27000 and 8 regional tiles of resolution 13500x13500. \n",
    "\n",
    "To calculate the approximate the light of a location, given its latitude and longitude: \n",
    "1. We find it pixel location on the map-like image, \n",
    "2. Calculate which tile image that location corresponds to, \n",
    "3. Transform the location to the the correct pixel location in the tile image which has higher resolution, \n",
    "4. Average the light over the neighboring pixels.\n",
    "\n",
    "![Locating Seattle on Night Satellite Image](night_time_example.png)\n",
    "\n",
    "### Percentage of Special Area Types + Roads\n",
    "\n",
    "When looking at high and low incomes during the day, it becomes apparent that high income areas tend to have amenities that are not available in low income areas.  These include well paved roads, parks, museums and other cultural centers.  So, it is natural to try to predict the average income of a city based on how developed the city seems to be, and how many attractions there are for residents to take part in.  The Google Static Maps API enable us to extract multiple area types from an image of a city.  These include natural land, man-made land, roads, water, areas of interest (museums and cultural centers), and parks.  We created features from this by taking the percentage of land in each city that belonged to each category.  \n",
    " \n",
    "### Number of Cars\n",
    "\n",
    "Another proxy for economic activity is the number of cars on the roads. Yes, some cities that are poorer than others will have more cars probably due to higher population density, but certainly cities that few to no cars will be the poorest. In order to extract the number of cars on the satellite-view Google Maps image we use a two-fold method: \n",
    "1. Template Matching \n",
    "2. Variance in the color of the roads\n",
    "\n",
    "Template matching is a technique in digital image processing for finding small parts of an image which match a template image. In our case, the template image is that of a car, and we use Canny edge detection to match it to our satellite image with the help of the openCV package (cv2). We take the edges of both the road pictures and the template picture, and compute the high similarity points (using the TM_COEFF_NORMED values), and rotate the template image around to account for different road directions.  Calling cv2.matchtemplate returns a grayscale image of correlation values according to the above function.  From these images (one for every rotation we do), we pick out values that are above a threshold and use those to be the number of car \"pixels\" in the image.  We then take the percentage of car pixels to be one of the features in the SVM.\n",
    "\n",
    "We also used the satellite-view to find the variance in the color of the roads. This metric has multiple uses for us.  The foremost is that it gives us an indication of the quality of roads in a city, as well paved roads tend to be uniform, and poorly maintained roads will have dirt and grass growing.  It also hints at the number of cars on the road because more the number of cars implies the presence of varied colors in the region of the road, so we wanted to see what impact this feature would have on the overall predictions. Since we already know exactly where the roads are, from the road-map, we can easily find the variance in the color of the pixels corresponding the to the region of the roads, which would give us the required feature. \n",
    "\n",
    "Both these features in tandem would give us a good handle on the condition of automotive travel in different cities.  While we thought this would be a good predictor for American cities, where car travel is popular, we were also concerned that in European cities that are incredibly wealthy yet don't have many car owners, this may be a false herring for the SVM.\n",
    "\n",
    "![Car Edge Template](car_template.png)\n",
    "![Car Example](car_example.png)\n",
    "\n",
    "\n",
    "## Training\n",
    "\n",
    "Finally we use a trained Support Vector Machine to classify new data.  We obtained our training data from http://www.city-data.com/ , which features highly detailed data profiles of all cities in the United States. We used Scikit-learn's SVR to train and predict on our features.  After testing all of the kernels we found that the RBF and sigmoid kernels gave us almost constant predictions for every city, so they were not useful. Of the  poly and linear kernels, the linear one gave us the best fit in the middle range, and the poly kernel was able to predict well for outliers, such as Zurich Switzerland (which has the highest average income in the world).  Ultimately we decided that the linear kernel would be the best for us.\n",
    "\n",
    "## Code\n",
    "\n",
    "For simplicity, we have abstracted everything into a WealthPredictor class that takes in a list of latitude/longitude bounding boxes (as proxies for city definitions) and then the corresponding income per capita values for training. You can predict the income per capita for a list of cities (again, represented as latitude/longitude bounding boxes). We will go over some of the critical code after showing an example of training and predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training WealthPredictor...\n",
      "Done!\n",
      "Predicting test coordinates...\n",
      "[ 38231.5  38231.5  38231.5]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Import the WealthPredictor class\n",
    "from wealth_predictor import WealthPredictor\n",
    "\n",
    "# City labels just for reference\n",
    "# Note the mix of sizes and income levels for the training data\n",
    "training_places = [\"San Fransisco, CA\", \"DC\", \"Blackwater, AZ\", \"Sneedsville, TN\", \"Newtonn, MA\", \"Mamou, LA\"]\n",
    "training_coords = [((37.710978, -122.500087), (37.802606, -122.404110)),\n",
    "          ((38.819597, -77.160145), (38.983113, -76.912953)),\n",
    "          ((33.000521, -111.664691), (33.045859, -111.568733)),\n",
    "          ((36.513680, -83.234828), (36.555887, -83.166506)),\n",
    "         ((42.288678, -71.267065), (42.366094, -71.160635)), \n",
    "         ((30.624943, -92.425908), (30.644181, -92.410887))]\n",
    "training_labels = [63024, 57291, 9491, 13719, 102796, 19172]\n",
    "\n",
    "print \"Training WealthPredictor...\"\n",
    "# Specify the zoom level. Zoom must be between 12 (city zoom) and 20 (street zoom).\n",
    "# For best results that are timely, we recommend zoom between 14 and 16.\n",
    "wp = WealthPredictor(15)\n",
    "wp.train(training_coords, training_labels)\n",
    "print \"Done!\"\n",
    "\n",
    "# Again, city labels just for reference\n",
    "training_places = [\"University Park, NM\", \"Pittsburgh, PA\", \"Tenafly, NJ\"]\n",
    "test_coords = [((32.263894, -106.765491), (32.285883, -106.739656)),\n",
    "               ((40.417268, -80.036749), (40.418268, -80.035749)),\n",
    "               ((40.901511, -73.982347), (40.936339, -73.930420))]\n",
    "test_labels = [5520, 28176, 73846]\n",
    "\n",
    "print \"Predicting test coordinates...\"\n",
    "print wp.predict(test_coords)\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "From our Wealth predictor, we were able to run on the following 3 cities: University Park, New Mexico, Pittsburgh, PA, and Tenafly, NJ.  Our results were very promising, as the predictor predicted 11933.62771502, 89800.60751067, and 137396.21477934 as average incomes for these 3 cities.  The real incomes for University park and Tenafly were around 13000 and 100000, which indicates that the SVR was able to pickout key features that identified the whether or not the places were wealthy.  While it was not perfect in determining their exact incomes, it did a good job seperating very wealthy cities from very poor cities, which shows promise in we had more time to generate training data and test data.  \n",
    "\n",
    "![Example of a styled image](example_styled.png)\n",
    "![Rate-limiting in action](rate_limiting.png)\n",
    "\n",
    "## Improvement\n",
    "\n",
    "We encountered a number of problems along the way, one of which was that the google static maps API only allows 25000 pictures within a 24 hour period.  Our program scans over a very large area at very high zooms, and as a result we would often require hundreds or thousands of pictures to process a large city like New York or San Fransisco.  Unforunately this meant we quickly exceeded this number when testing, and were unable to get more training data and testing data to run our program on.  If we had more data, we believe that there is great promise for our features to be able to accurately predict the wealth of cities around the world.  We also believe that there are more we can do to split areas of interest up, in order to get a finer regression of our data.  One of these would be to label park space and other areas of interest differently.  We also noticed that google static maps gives us access to shipping lanes, which we were unable to use in our program due to lack of training data.  It seems reasonable that cities with lots of shipping lanes would be centers of trade, and have high average income as a result.  Although this may also have no correlation to average income, as many landlocked cities rank among the highest average incomes, and many trade routes go through land and air.  Additionally, we are interested in testing how our algorithm performs against algorithms like PCA and unsupervised learning algorithms (like performing K means on the pictures and predicting the average income of pictures in each cluster).  Overall, there is a lot that can be done to improve this algorithm and thinking style, and if given more time we would have worked to accomplishing these goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
